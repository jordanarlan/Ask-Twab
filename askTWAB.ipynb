{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jorda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jorda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jorda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'NextPaginationToken'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo NewsArticles found in the response.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     page_token \u001b[39m=\u001b[39m json_response[\u001b[39m'\u001b[39;49m\u001b[39mResponse\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mNextPaginationToken\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError:\u001b[39m\u001b[39m\"\u001b[39m, response\u001b[39m.\u001b[39mstatus_code)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NextPaginationToken'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from importlib.machinery import SourceFileLoader\n",
    "import pinecone\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "config = SourceFileLoader(\"config\", \"config.py\").load_module()\n",
    "os.environ['OPENAI_API_KEY'] = config.OPENAI_API_KEY\n",
    "\n",
    "bungie_api_key = config.BUNGIE_API_KEY\n",
    "endpoint = \"https://www.bungie.net/Platform/Content/Rss/NewsArticles/{pageToken}/\"\n",
    "page_token = \"0\"\n",
    "include_body = True\n",
    "headers = {\n",
    "    \"X-API-Key\": bungie_api_key\n",
    "}\n",
    "params = {\n",
    "    \"includebody\": include_body\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "while page_token is not None:\n",
    "    response = requests.get(endpoint.format(pageToken=page_token), headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        json_response = response.json()\n",
    "        if 'NewsArticles' in json_response['Response']:\n",
    "            results.extend(json_response['Response']['NewsArticles'])\n",
    "        else:\n",
    "            print(\"No NewsArticles found in the response.\")\n",
    "            break\n",
    "        page_token = json_response['Response']['NextPaginationToken']\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Results: 1014\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Results: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                                               Destiny 2 Hotfix 6/02/23\n",
       "Link                             /7/en/News/Article/destiny-2-hotfix-6-02-23\n",
       "PubDate                                                 2023-06-03T04:52:00Z\n",
       "UniqueIdentifier                                         blt612fd6dfe9162c9d\n",
       "Description                                            The one about a horn.\n",
       "HtmlContent                <h4>GENERAL</h4><ul><li>Due to an issue, the K...\n",
       "ImagePath                  https://images.contentstack.io/v3/assets/blte4...\n",
       "OptionalMobileImagePath    https://images.contentstack.io/v3/assets/blte4...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results list into a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Destiny 2 Hotfix 6/02/23\n",
       "1         This Week At Bungie - 06/01/2023\n",
       "2                 Destiny 2 Update 7.1.0.1\n",
       "3                 Community Focus - Plumli\n",
       "4                 Destiny 2 Hotfix 5/26/23\n",
       "                       ...                \n",
       "1009           Potentially Asked Questions\n",
       "1010             Inside the new Bungie.net\n",
       "1011                        This is a Test\n",
       "1012    Happy 10th Anniversary, Xbox LIVE!\n",
       "1013              Breaking In - Adam Brown\n",
       "Name: Title, Length: 1014, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         Destiny 2 Hotfix 6/02/23\n",
       "1                 This Week At Bungie - 06/01/2023\n",
       "2                         Destiny 2 Update 7.1.0.1\n",
       "3                         Destiny 2 Hotfix 5/26/23\n",
       "4      Destiny 2 Update 7.1.0 - Season of the Deep\n",
       "                          ...                     \n",
       "330               This Week At Bungie - 03/03/2016\n",
       "331               This Week At Bungie - 02/25/2016\n",
       "332               This Week At Bungie - 02/18/2016\n",
       "333               This Week At Bungie – 02/11/2016\n",
       "334               This Week At Bungie – 02/04/2016\n",
       "Name: Title, Length: 335, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Title'].str.startswith(('This Week At Bungie', 'Destiny 2'))]\n",
    "df = df.reset_index()\n",
    "# Print the filtered DataFrame\n",
    "df['Title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                      0\n",
       "Title                                               Destiny 2 Hotfix 6/02/23\n",
       "Link                             /7/en/News/Article/destiny-2-hotfix-6-02-23\n",
       "PubDate                                                 2023-06-03T04:52:00Z\n",
       "UniqueIdentifier                                         blt612fd6dfe9162c9d\n",
       "Description                                            The one about a horn.\n",
       "HtmlContent                <h4>GENERAL</h4><ul><li>Due to an issue, the K...\n",
       "ImagePath                  https://images.contentstack.io/v3/assets/blte4...\n",
       "OptionalMobileImagePath    https://images.contentstack.io/v3/assets/blte4...\n",
       "clean_text                 GENERALDue to an issue, the Khepri's Horn exot...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'clean_text' in the DataFrame\n",
    "df['clean_text'] = ''\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    html_content = row['HtmlContent']\n",
    "    \n",
    "    # Create a BeautifulSoup object to parse the HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Retrieve the text content using the .get_text() method\n",
    "    clean_text = soup.get_text().strip()  # Apply strip() to remove leading/trailing whitespaces\n",
    "    \n",
    "    # Assign the clean text to the 'clean_text' column of the current row\n",
    "    df.at[index, 'clean_text'] = clean_text\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                      1\n",
       "Title                                       This Week At Bungie - 06/01/2023\n",
       "Link                                      /7/en/News/Article/06_01_2023_twab\n",
       "PubDate                                                 2023-06-01T18:00:00Z\n",
       "UniqueIdentifier                                         blt36382dc929299957\n",
       "Description                This week at Bungie, we fought the ghosts of t...\n",
       "HtmlContent                <p>Happy TWABsday, Guardians! How are you doin...\n",
       "ImagePath                  https://images.contentstack.io/v3/assets/blte4...\n",
       "OptionalMobileImagePath    https://images.contentstack.io/v3/assets/blte4...\n",
       "clean_text                 Happy TWABsday, Guardians! How are you doing!?...\n",
       "preproc_text               happy twabsday guardians how are you doing how...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'preproc_text' in the DataFrame\n",
    "df['preproc_text'] = ''\n",
    "\n",
    "# Convert text to lowercase\n",
    "df['preproc_text'] = df['clean_text'].str.lower()\n",
    "\n",
    "# Remove special characters and numbers\n",
    "df['preproc_text'] = df['preproc_text'].apply(lambda text: re.sub(r'[^a-zA-Z\\'-]', ' ', text))\n",
    "\n",
    "# Remove redundant whitespace\n",
    "df['preproc_text'] = df['preproc_text'].apply(lambda text: re.sub(r'\\s+', ' ', text.strip()))\n",
    "\n",
    "\n",
    "# Tokenization\n",
    "#df['preproc_text'] = df['preproc_text'].apply(lambda text: nltk.word_tokenize(text))\n",
    "\n",
    "# Remove stopwords\n",
    "#stopwords_set = set(stopwords.words('english'))\n",
    "#df['preproc_text'] = df['preproc_text'].apply(lambda tokens: [token for token in tokens if token not in stopwords_set])\n",
    "\n",
    "# Lemmatization\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "#df['preproc_text'] = df['preproc_text'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "# Join tokens back into sentences\n",
    "#df['preproc_text'] = df['preproc_text'].apply(lambda tokens: ' '.join(tokens))\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Title', 'PubDate', 'UniqueIdentifier', 'Description', 'preproc_text']\n",
    "subset_df = df[selected_columns].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Title               PubDate   \n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z  \\\n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z   \n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z   \n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z   \n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z   \n",
      "..                               ...                   ...   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "\n",
      "       UniqueIdentifier                                        Description   \n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...  \\\n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...   \n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...   \n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...   \n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...   \n",
      "..                  ...                                                ...   \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "\n",
      "                                         preproc_text  \n",
      "1   happy twabsday guardians how are you doing how...  \n",
      "1   st week in twab marathon was announced our new...  \n",
      "1   deep into a titan archology only to arrive fac...  \n",
      "1   s victory lap new bungie rewardsspeaking of th...  \n",
      "1   ebrate your hard-earned achievements head on o...  \n",
      "..                                                ...  \n",
      "99  aterial spawns added destination materials to ...  \n",
      "99  n intended the terminals for the tire game app...  \n",
      "99  ation for petra's quest missions were showing ...  \n",
      "99   materials upon completion lunar ghost bundle ...  \n",
      "99  raid perk would sometimes fail to activate if ...  \n",
      "\n",
      "[2106 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_rows(df, max_length=512, overlap=20):\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['preproc_text']\n",
    "        num_chunks = (len(text) - max_length) // (max_length - overlap) + 1\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            start = i * (max_length - overlap)\n",
    "            end = start + max_length\n",
    "\n",
    "            # Adjust the end position to avoid splitting words\n",
    "            if end < len(text) and not text[end].isspace():\n",
    "                while end < len(text) and not text[end].isspace():\n",
    "                    end -= 1\n",
    "\n",
    "            new_row = row.copy()\n",
    "            new_row['preproc_text'] = text[start:end]\n",
    "            rows.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "split_df = split_rows(subset_df)\n",
    "\n",
    "# Print the resulting split DataFrame\n",
    "print(split_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2106"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key = config.pinecone_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to pinecone environment\n",
    "pinecone.init(\n",
    "    api_key = pinecone_api_key,\n",
    "    environment = \"us-west1-gcp-free\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"extractive-question-answering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extractive-question-answering']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pinecone.delete_index(\"extractive-question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the extractive-question-answering index exists\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # create the index if it does not exist\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "# connect to extractive-question-answering index we created\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)5fedf/.gitattributes: 100%|██████████| 737/737 [00:00<?, ?B/s] \n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<?, ?B/s] \n",
      "Downloading (…)2cb455fedf/README.md: 100%|██████████| 11.5k/11.5k [00:00<?, ?B/s]\n",
      "Downloading (…)b455fedf/config.json: 100%|██████████| 612/612 [00:00<?, ?B/s] \n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<?, ?B/s] \n",
      "Downloading (…)edf/data_config.json: 100%|██████████| 25.5k/25.5k [00:00<00:00, 25.4MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:00<00:00, 108MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 52.8kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n",
      "Downloading (…)5fedf/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 21.9MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 383/383 [00:00<00:00, 383kB/s]\n",
      "Downloading (…)fedf/train_script.py: 100%|██████████| 13.8k/13.8k [00:00<?, ?B/s]\n",
      "Downloading (…)2cb455fedf/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 116MB/s]\n",
      "Downloading (…)455fedf/modules.json: 100%|██████████| 349/349 [00:00<00:00, 348kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# set device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# load the retriever model from huggingface model hub\n",
    "retriever = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1', device=device)\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:27<00:00,  1.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 2106}},\n",
       " 'total_vector_count': 2106}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# we will use batches of 64\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(split_df), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(split_df))\n",
    "    # extract batch\n",
    "    batch = split_df.iloc[i:i_end]\n",
    "    # generate embeddings for batch\n",
    "    emb = retriever.encode(batch[\"preproc_text\"].tolist()).tolist()\n",
    "    # get metadata\n",
    "    meta = batch.to_dict(orient=\"records\")\n",
    "    # create unique IDs\n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
    "    # add all to upsert list\n",
    "    to_upsert = list(zip(ids, emb, meta))\n",
    "    # upsert/insert these records to pinecone\n",
    "    _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "# check that we have all vectors in index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 635/635 [00:00<?, ?B/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 436M/436M [00:10<00:00, 41.4MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 200/200 [00:00<?, ?B/s] \n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 12.6MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"deepset/electra-base-squad2\"\n",
    "# load the reader model into a question-answering pipeline\n",
    "reader = pipeline(tokenizer=model_name, model=model_name, task=\"question-answering\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"rail cannon projectiles will no longer deal flyby damage the offending damage that was framerate dependent they will now only apply damage on direct hits but will hit you a bit more often average damage output is about the same as you'd receive at fps fixed various issues where some how to toasts were set to a higher priority than some system messages fixed an issue where ultra combatants' health bars were not consistently respecting colorblind settings ultra-combatant health bars would display inconsistent\"]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets context passages from the pinecone index\n",
    "def get_context(question, top_k):\n",
    "    # generate embeddings for the question\n",
    "    xq = retriever.encode([question]).tolist()\n",
    "    # search pinecone index for context passage with the answer\n",
    "    xc = index.query(xq, top_k=top_k, include_metadata=True)\n",
    "    # extract the context passage from pinecone search result\n",
    "    c = [x[\"metadata\"][\"preproc_text\"] for x in xc[\"matches\"]]\n",
    "    return c\n",
    "\n",
    "question = \"how much damage do aggressive frame smgs do now?\"\n",
    "context = get_context(question, top_k = 1)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'only apply damage on direct hits',\n",
      "  'end': 153,\n",
      "  'preproc_text': 'rail cannon projectiles will no longer deal flyby damage '\n",
      "                  'the offending damage that was framerate dependent they will '\n",
      "                  'now only apply damage on direct hits but will hit you a bit '\n",
      "                  \"more often average damage output is about the same as you'd \"\n",
      "                  'receive at fps fixed various issues where some how to '\n",
      "                  'toasts were set to a higher priority than some system '\n",
      "                  \"messages fixed an issue where ultra combatants' health bars \"\n",
      "                  'were not consistently respecting colorblind settings '\n",
      "                  'ultra-combatant health bars would display inconsistent',\n",
      "  'score': 0.005786481779068708,\n",
      "  'start': 121}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# extracts answer from the context passage\n",
    "def extract_answer(question, context):\n",
    "    results = []\n",
    "    for c in context:\n",
    "        # feed the reader the question and contexts to extract answers\n",
    "        answer = reader(question=question, context=c)\n",
    "        # add the context to answer dict for printing both together\n",
    "        answer[\"preproc_text\"] = c\n",
    "        results.append(answer)\n",
    "    # sort the result based on the score from reader model\n",
    "    sorted_result = pprint(sorted(results, key=lambda x: x[\"score\"], reverse=True))\n",
    "    return sorted_result\n",
    "\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'graviton',\n",
      "  'end': 122,\n",
      "  'preproc_text': ' and keyboard recoil penalty from to arbalest reduced '\n",
      "                  'damage vs champions by will still break barriers in one hit '\n",
      "                  'graviton lance catalyst changed from granting hidden hand '\n",
      "                  'to granting vorpal weapon and turnabout grand overture '\n",
      "                  'reduced time between bursts when in missile mode holding '\n",
      "                  'the trigger will now fire all missiles in a continuous '\n",
      "                  'burst tapping will fire -round bursts wavesplitter - void '\n",
      "                  'update picking up an orb of power now grants s of maximum '\n",
      "                  'power and caps at s up from and respectively now',\n",
      "  'score': 0.23234397172927856,\n",
      "  'start': 114}]\n"
     ]
    }
   ],
   "source": [
    "question = \"What were the changes to graviton\"\n",
    "context = get_context(question, top_k=1)\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'guardian games triumphs',\n",
      "  'end': 58,\n",
      "  'preproc_text': 'layed as winner for the event some guardian games triumphs '\n",
      "                  'are activating earlier than intended as a result the titles '\n",
      "                  'tab now flashes as though something is unlocked these '\n",
      "                  'triumphs will be able to be claimed when guardian games '\n",
      "                  'launches in two weeks the zone control playlist doesn t '\n",
      "                  'display an increased crucible rank modifier dying in the '\n",
      "                  'hypernet current strike s boss room can sometimes get a '\n",
      "                  'player s ghost stuck in the floor quitter penalties were '\n",
      "                  'erroneously enabled with launch for completing matches',\n",
      "  'score': 1.445486130791096e-08,\n",
      "  'start': 35}]\n"
     ]
    }
   ],
   "source": [
    "question = \"who won guardian games?\"\n",
    "context = get_context(question, top_k=1)\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'changes',\n",
      "  'end': 512,\n",
      "  'preproc_text': ' through hostile titan barricades barricades now slightly '\n",
      "                  \"protrude into the ground to better protect the titan's feet \"\n",
      "                  'on uneven ground this should reduce instances where '\n",
      "                  'explosions and projectiles are able to sneak through the '\n",
      "                  'bottom of the barricade and hit the titan behemoth as you '\n",
      "                  'may remember midway through last season we released a '\n",
      "                  'portion of the stasis-related changes originally intended '\n",
      "                  'for this releasen we re pretty happy with the effect those '\n",
      "                  'changes have had on the crucible but some of the changes',\n",
      "  'score': 2.4935166820228005e-08,\n",
      "  'start': 505},\n",
      " {'answer': 'replace barricades with just a single ice block',\n",
      "  'end': 449,\n",
      "  'preproc_text': 'h this one takes a chillier approach to combat for stasis '\n",
      "                  'users with the glacial fortification perk when a player '\n",
      "                  'uses stasis it allows for a titan s barricade to become an '\n",
      "                  'impressive wall of stasis crystals these crystals will slow '\n",
      "                  'any target that gets too close while also boosting a player '\n",
      "                  'and their fireteam s weapon reload speed stability and '\n",
      "                  'range this was a team effort the original idea was to '\n",
      "                  'replace barricades with just a single ice block but kevin '\n",
      "                  'yanes and the abilities team had some ideas and',\n",
      "  'score': 2.3035665819293172e-08,\n",
      "  'start': 402},\n",
      " {'answer': 'titan',\n",
      "  'end': 432,\n",
      "  'preproc_text': ' reduced cooldown from s to s bottom-tree nightstalker '\n",
      "                  'vanish in smoke melee reduced cooldown from s to s revenant '\n",
      "                  'grim harvest aspect increased fragment slots from two to '\n",
      "                  'three shatterdive increased damage vs frozen pve combatants '\n",
      "                  'by note is much less lethal vs players due to stasis '\n",
      "                  'crystal changes withering blade increased cooldown from s '\n",
      "                  'to s warlock uncharged melee reduced melee range from m to '\n",
      "                  'm now matches hunter and titan reduced suppression time '\n",
      "                  'after melee can now melee back-to-back at the same',\n",
      "  'score': 3.3804581356378094e-10,\n",
      "  'start': 427}]\n"
     ]
    }
   ],
   "source": [
    "question = \"what were the most recent changes to stasis titan?\"\n",
    "context = get_context(question, top_k=3)\n",
    "extract_answer(question, context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
