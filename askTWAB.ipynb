{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jorda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jorda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jorda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'NextPaginationToken'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo NewsArticles found in the response.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     page_token \u001b[39m=\u001b[39m json_response[\u001b[39m'\u001b[39;49m\u001b[39mResponse\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mNextPaginationToken\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError:\u001b[39m\u001b[39m\"\u001b[39m, response\u001b[39m.\u001b[39mstatus_code)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NextPaginationToken'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from importlib.machinery import SourceFileLoader\n",
    "import pinecone\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "config = SourceFileLoader(\"config\", \"config.py\").load_module()\n",
    "os.environ['OPENAI_API_KEY'] = config.OPENAI_API_KEY\n",
    "\n",
    "bungie_api_key = config.BUNGIE_API_KEY\n",
    "endpoint = \"https://www.bungie.net/Platform/Content/Rss/NewsArticles/{pageToken}/\"\n",
    "page_token = \"0\"\n",
    "include_body = True\n",
    "headers = {\n",
    "    \"X-API-Key\": bungie_api_key\n",
    "}\n",
    "params = {\n",
    "    \"includebody\": include_body\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "while page_token is not None:\n",
    "    response = requests.get(endpoint.format(pageToken=page_token), headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        json_response = response.json()\n",
    "        if 'NewsArticles' in json_response['Response']:\n",
    "            results.extend(json_response['Response']['NewsArticles'])\n",
    "        else:\n",
    "            print(\"No NewsArticles found in the response.\")\n",
    "            break\n",
    "        page_token = json_response['Response']['NextPaginationToken']\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Results: 1014\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Results: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                                               Destiny 2 Hotfix 6/02/23\n",
       "Link                             /7/en/News/Article/destiny-2-hotfix-6-02-23\n",
       "PubDate                                                 2023-06-03T04:52:00Z\n",
       "UniqueIdentifier                                         blt612fd6dfe9162c9d\n",
       "Description                                            The one about a horn.\n",
       "HtmlContent                <h4>GENERAL</h4><ul><li>Due to an issue, the K...\n",
       "ImagePath                  https://images.contentstack.io/v3/assets/blte4...\n",
       "OptionalMobileImagePath    https://images.contentstack.io/v3/assets/blte4...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results list into a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Destiny 2 Hotfix 6/02/23\n",
       "1         This Week At Bungie - 06/01/2023\n",
       "2                 Destiny 2 Update 7.1.0.1\n",
       "3                 Community Focus - Plumli\n",
       "4                 Destiny 2 Hotfix 5/26/23\n",
       "                       ...                \n",
       "1009           Potentially Asked Questions\n",
       "1010             Inside the new Bungie.net\n",
       "1011                        This is a Test\n",
       "1012    Happy 10th Anniversary, Xbox LIVE!\n",
       "1013              Breaking In - Adam Brown\n",
       "Name: Title, Length: 1014, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         Destiny 2 Hotfix 6/02/23\n",
       "1                 This Week At Bungie - 06/01/2023\n",
       "2                         Destiny 2 Update 7.1.0.1\n",
       "3                         Destiny 2 Hotfix 5/26/23\n",
       "4      Destiny 2 Update 7.1.0 - Season of the Deep\n",
       "                          ...                     \n",
       "330               This Week At Bungie - 03/03/2016\n",
       "331               This Week At Bungie - 02/25/2016\n",
       "332               This Week At Bungie - 02/18/2016\n",
       "333               This Week At Bungie – 02/11/2016\n",
       "334               This Week At Bungie – 02/04/2016\n",
       "Name: Title, Length: 335, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Title'].str.startswith(('This Week At Bungie', 'Destiny 2'))]\n",
    "df = df.reset_index()\n",
    "# Print the filtered DataFrame\n",
    "df['Title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                      0\n",
       "Title                                               Destiny 2 Hotfix 6/02/23\n",
       "Link                             /7/en/News/Article/destiny-2-hotfix-6-02-23\n",
       "PubDate                                                 2023-06-03T04:52:00Z\n",
       "UniqueIdentifier                                         blt612fd6dfe9162c9d\n",
       "Description                                            The one about a horn.\n",
       "HtmlContent                <h4>GENERAL</h4><ul><li>Due to an issue, the K...\n",
       "ImagePath                  https://images.contentstack.io/v3/assets/blte4...\n",
       "OptionalMobileImagePath    https://images.contentstack.io/v3/assets/blte4...\n",
       "clean_text                 GENERALDue to an issue, the Khepri's Horn exot...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'clean_text' in the DataFrame\n",
    "df['clean_text'] = ''\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    html_content = row['HtmlContent']\n",
    "    \n",
    "    # Create a BeautifulSoup object to parse the HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Retrieve the text content using the .get_text() method\n",
    "    clean_text = soup.get_text().strip()  # Apply strip() to remove leading/trailing whitespaces\n",
    "    \n",
    "    # Assign the clean text to the 'clean_text' column of the current row\n",
    "    df.at[index, 'clean_text'] = clean_text\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                      1\n",
       "Title                                       This Week At Bungie - 06/01/2023\n",
       "Link                                      /7/en/News/Article/06_01_2023_twab\n",
       "PubDate                                                 2023-06-01T18:00:00Z\n",
       "UniqueIdentifier                                         blt36382dc929299957\n",
       "Description                This week at Bungie, we fought the ghosts of t...\n",
       "HtmlContent                <p>Happy TWABsday, Guardians! How are you doin...\n",
       "ImagePath                  https://images.contentstack.io/v3/assets/blte4...\n",
       "OptionalMobileImagePath    https://images.contentstack.io/v3/assets/blte4...\n",
       "clean_text                 Happy TWABsday, Guardians! How are you doing!?...\n",
       "preproc_text               happy twabsday guardians how are you doing how...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'preproc_text' in the DataFrame\n",
    "df['preproc_text'] = ''\n",
    "\n",
    "# Convert text to lowercase\n",
    "df['preproc_text'] = df['clean_text'].str.lower()\n",
    "\n",
    "# Remove special characters and numbers\n",
    "df['preproc_text'] = df['preproc_text'].apply(lambda text: re.sub(r'[^a-zA-Z\\'-]', ' ', text))\n",
    "\n",
    "# Remove redundant whitespace\n",
    "df['preproc_text'] = df['preproc_text'].apply(lambda text: re.sub(r'\\s+', ' ', text.strip()))\n",
    "\n",
    "\n",
    "# Tokenization\n",
    "#df['preproc_text'] = df['preproc_text'].apply(lambda text: nltk.word_tokenize(text))\n",
    "\n",
    "# Remove stopwords\n",
    "#stopwords_set = set(stopwords.words('english'))\n",
    "#df['preproc_text'] = df['preproc_text'].apply(lambda tokens: [token for token in tokens if token not in stopwords_set])\n",
    "\n",
    "# Lemmatization\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "#df['preproc_text'] = df['preproc_text'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "# Join tokens back into sentences\n",
    "#df['preproc_text'] = df['preproc_text'].apply(lambda tokens: ' '.join(tokens))\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Title', 'PubDate', 'UniqueIdentifier', 'Description', 'preproc_text']\n",
    "subset_df = df[selected_columns].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Title               PubDate   \n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z  \\\n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z   \n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z   \n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z   \n",
      "1   This Week At Bungie - 06/01/2023  2023-06-01T18:00:00Z   \n",
      "..                               ...                   ...   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "99            Destiny 2 Update 3.0.1  2020-12-08T16:59:39Z   \n",
      "\n",
      "       UniqueIdentifier                                        Description   \n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...  \\\n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...   \n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...   \n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...   \n",
      "1   blt36382dc929299957  This week at Bungie, we fought the ghosts of t...   \n",
      "..                  ...                                                ...   \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "99  blt567c70367c1be485                   The one about next-gen upgrades    \n",
      "\n",
      "                                         preproc_text  \n",
      "1   happy twabsday guardians how are you doing how...  \n",
      "1   ets us pretty hyped anyhoo let s get back on t...  \n",
      "1   he deep recap dungeon-themed items in the bung...  \n",
      "1   es and wizards show as a blip on your radar on...  \n",
      "1   ians you deserve this victory lap new bungie r...  \n",
      "..                                                ...  \n",
      "99  r above high-value targets appropriately dream...  \n",
      "99  fore public events nessus fixed an issue where...  \n",
      "99  ls upon completion lunar ghost bundle no longe...  \n",
      "99  xed a bug where some new armor mods had incorr...  \n",
      "99  here the hit list was not unlocking properly f...  \n",
      "\n",
      "[2868 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_rows(df, max_length=384, overlap=20):\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['preproc_text']\n",
    "        num_chunks = (len(text) - max_length) // (max_length - overlap) + 1\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            start = i * (max_length - overlap)\n",
    "            end = start + max_length\n",
    "\n",
    "            # Adjust the end position to avoid splitting words\n",
    "            if end < len(text) and not text[end].isspace():\n",
    "                while end < len(text) and not text[end].isspace():\n",
    "                    end -= 1\n",
    "\n",
    "            new_row = row.copy()\n",
    "            new_row['preproc_text'] = text[start:end]\n",
    "            rows.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "split_df = split_rows(subset_df)\n",
    "\n",
    "# Print the resulting split DataFrame\n",
    "print(split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2868"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key = config.pinecone_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to pinecone environment\n",
    "pinecone.init(\n",
    "    api_key = pinecone_api_key,\n",
    "    environment = \"us-west1-gcp-free\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"extractive-question-answering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extractive-question-answering']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.delete_index(\"extractive-question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the extractive-question-answering index exists\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # create the index if it does not exist\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "# connect to extractive-question-answering index we created\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# set device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# load the retriever model from huggingface model hub\n",
    "retriever = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [01:42<00:00,  2.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 2816}},\n",
       " 'total_vector_count': 2816}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# we will use batches of 64\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(split_df), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(split_df))\n",
    "    # extract batch\n",
    "    batch = split_df.iloc[i:i_end]\n",
    "    # generate embeddings for batch\n",
    "    emb = retriever.encode(batch[\"preproc_text\"].tolist()).tolist()\n",
    "    # get metadata\n",
    "    meta = batch.to_dict(orient=\"records\")\n",
    "    # create unique IDs\n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
    "    # add all to upsert list\n",
    "    to_upsert = list(zip(ids, emb, meta))\n",
    "    # upsert/insert these records to pinecone\n",
    "    _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "# check that we have all vectors in index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"deepset/electra-base-squad2\"\n",
    "# load the reader model into a question-answering pipeline\n",
    "reader = pipeline(tokenizer=model_name, model=model_name, task=\"question-answering\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"e an airborne accuracy penalty are there any changes to aggressive aka spread fusion rifles no they're not affected by any of the fusion rifle tuning do all smgs benefit from the damage falloff increase yes do all smgs with lower than zoom now have no only those listed in the twab have been raised to what happened to the full-auto setting we mentioned that this is coming in a\"]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets context passages from the pinecone index\n",
    "def get_context(question, top_k):\n",
    "    # generate embeddings for the question\n",
    "    xq = retriever.encode([question]).tolist()\n",
    "    # search pinecone index for context passage with the answer\n",
    "    xc = index.query(xq, top_k=top_k, include_metadata=True)\n",
    "    # extract the context passage from pinecone search result\n",
    "    c = [x[\"metadata\"][\"preproc_text\"] for x in xc[\"matches\"]]\n",
    "    return c\n",
    "\n",
    "question = \"how much damage do aggressive frame smgs do now?\"\n",
    "context = get_context(question, top_k = 1)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'damage falloff increase yes do all smgs with lower than zoom now '\n",
      "            'have',\n",
      "  'end': 248,\n",
      "  'preproc_text': 'e an airborne accuracy penalty are there any changes to '\n",
      "                  \"aggressive aka spread fusion rifles no they're not affected \"\n",
      "                  'by any of the fusion rifle tuning do all smgs benefit from '\n",
      "                  'the damage falloff increase yes do all smgs with lower than '\n",
      "                  'zoom now have no only those listed in the twab have been '\n",
      "                  'raised to what happened to the full-auto setting we '\n",
      "                  'mentioned that this is coming in a',\n",
      "  'score': 5.2150696955299836e-11,\n",
      "  'start': 179}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# extracts answer from the context passage\n",
    "def extract_answer(question, context):\n",
    "    results = []\n",
    "    for c in context:\n",
    "        # feed the reader the question and contexts to extract answers\n",
    "        answer = reader(question=question, context=c)\n",
    "        # add the context to answer dict for printing both together\n",
    "        answer[\"preproc_text\"] = c\n",
    "        results.append(answer)\n",
    "    # sort the result based on the score from reader model\n",
    "    sorted_result = pprint(sorted(results, key=lambda x: x[\"score\"], reverse=True))\n",
    "    return sorted_result\n",
    "\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'glaive melee base damage reduced from to grenade launchers',\n",
      "  'end': 183,\n",
      "  'preproc_text': 'laive melee damage multipliers reduced by - against '\n",
      "                  'champions minibosses bosses and vehicles majors and minors '\n",
      "                  'are unchanged glaive melee base damage reduced from to '\n",
      "                  'grenade launchers the queenbreaker and grand '\n",
      "                  'overtureswitched from the old blinding screen effect to the '\n",
      "                  'new arc blind one with reduced screen effect brightness '\n",
      "                  'hand cannonrose has new stats increased range from to',\n",
      "  'score': 0.6456788182258606,\n",
      "  'start': 125}]\n"
     ]
    }
   ],
   "source": [
    "question = \"What were the changes to graviton\"\n",
    "context = get_context(question, top_k=1)\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'fireteams of guardians',\n",
      "  'end': 210,\n",
      "  'preproc_text': 'ntures to be had and rewards to be won are you pumped yet '\n",
      "                  'well watch this on top of the overall class vs class main '\n",
      "                  'event we have also assembled a friendly out-of-game '\n",
      "                  'competition between fireteams of guardians from across the '\n",
      "                  'globe we have creators from territories representing their '\n",
      "                  'favorite class and competing for glory in the guardian '\n",
      "                  'games cup check out the full details and',\n",
      "  'score': 2.550037606852129e-06,\n",
      "  'start': 188}]\n"
     ]
    }
   ],
   "source": [
    "question = \"who won guardian games?\"\n",
    "context = get_context(question, top_k=1)\n",
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'non-lethal collision damage changes',\n",
      "  'end': 272,\n",
      "  'preproc_text': 'fting table now provide slight stat increases veriglas '\n",
      "                  \"curve fixed an issue causing verglas curve's stasis \"\n",
      "                  'crystals to fail to spawn if shot at a titan bubble tractor '\n",
      "                  'cannon fixed an issue where tractor cannon was impacted by '\n",
      "                  'the recent non-lethal collision damage changes now causes '\n",
      "                  'hit targets to be able to suffer lethal collision damage '\n",
      "                  'for a brief duration thunderlord fixed an',\n",
      "  'score': 0.451644629240036,\n",
      "  'start': 237},\n",
      " {'answer': 'now works with stasis subclasses as intended',\n",
      "  'end': 187,\n",
      "  'preproc_text': 'pauldrons in pvp game modes reduced super-energy gain by '\n",
      "                  \"shinobu's vow in pvp game modes reduced grenade-energy gain \"\n",
      "                  'per hit by chromatic fire now works with stasis subclasses '\n",
      "                  'as intended crown of tempests in pvp game modes reduced '\n",
      "                  'energy-regeneration boost duration from s to s the stag in '\n",
      "                  'pvp game modes reduced class-ability energy gain by icefall '\n",
      "                  'mantle stasis overshield can now',\n",
      "  'score': 0.0001305731275351718,\n",
      "  'start': 143},\n",
      " {'answer': 'titan shoulder charge abilities',\n",
      "  'end': 297,\n",
      "  'preproc_text': ' damage vs players from to reduced detonation radius in pvp '\n",
      "                  'game modes from m to m whisper of rending increased '\n",
      "                  'kinetic-weapon damage vs stasis crystals by frozen status '\n",
      "                  'effect fixed an issue where frozen players could still '\n",
      "                  'interact with objects and revive players titan shoulder '\n",
      "                  'charge abilities seismic strike hammer strike shield bash '\n",
      "                  'sprint activation time reduced from s to s',\n",
      "  'score': 1.7791786603993387e-06,\n",
      "  'start': 266}]\n"
     ]
    }
   ],
   "source": [
    "question = \"what were the most recent changes to stasis titan?\"\n",
    "context = get_context(question, top_k=3)\n",
    "extract_answer(question, context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
